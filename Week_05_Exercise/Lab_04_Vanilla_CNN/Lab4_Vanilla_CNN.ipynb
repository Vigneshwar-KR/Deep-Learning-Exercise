{"cells":[{"cell_type":"markdown","metadata":{"id":"tnpOp1yOWIJT"},"source":["# **Course**: Deep Learning\n","\n","[<img align=\"right\" width=\"400\" height=\"100\" src=\"https://www.tu-braunschweig.de/typo3conf/ext/tu_braunschweig/Resources/Public/Images/Logos/tu_braunschweig_logo.svg\">](https://www.tu-braunschweig.de/en/)\n","\n","[Mehdi Maboudi](https://www.tu-braunschweig.de/en/igp/staff/mehdi-maboudi) \\([m.maboudi@tu-bs.de](m.maboudi@tu-bs.de)) and [Pedro Achanccaray](https://www.tu-braunschweig.de/en/igp/staff/pedro-diaz) (p.diaz@tu-bs.de)\n","\n","[Technical University of Braunschweig](https://www.tu-braunschweig.de/en/)  \n","[Institute of Geodesy and Photogrammetry](https://www.tu-braunschweig.de/igp)"]},{"cell_type":"markdown","metadata":{"id":"KhB2v5lPAYvF"},"source":["# **Administrative topics**"]},{"cell_type":"markdown","metadata":{"id":"8FJBVQ_JAbAm"},"source":["**Presentation 01: Datasets**\n","- Presentation: 10 min., Questions: 5 min\n","- Update your repositories: code and presentation (PDF and/or PPTX)"]},{"cell_type":"markdown","metadata":{"id":"GCZeFSPlAfEh"},"source":["# **Assignment 03:** Vanilla CNN"]},{"cell_type":"markdown","metadata":{"id":"JOjbezx9AtZR"},"source":["Let's see each group solution.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dmOB7awVHdOQ"},"source":["## **One possible solution**"]},{"cell_type":"markdown","source":["### In the file **`datasets.py`**"],"metadata":{"id":"J-XSWVHeBzRa"}},{"cell_type":"markdown","source":["- **`train_val_test_split`** function:\n","```python\n","  # TODO: Train and test split. Use test_size here.  \n","  x_train, x_test, y_train, y_test = train_test_split(df[\"path_image\"].values,\n","                                                      df[\"class_int\"].values,                                                     \n","                                                      test_size=test_size,\n","                                                      stratify=df[\"class_int\"].values,\n","                                                      random_state=SEED)\n","\n","  val_size_relative = val_size/(1-test_size)\n","  # TODO: Train and validation split. Use val_size_relative here.  \n","  x_train, x_val, y_train, y_val = train_test_split(x_train,\n","                                                    y_train,\n","                                                    test_size=val_size_relative,\n","                                                    stratify=y_train,\n","                                                    random_state=SEED)\n","```\n","\n"],"metadata":{"id":"KNXPc4pg-eQf"}},{"cell_type":"markdown","source":["### In the file **`data_generator.py`**"],"metadata":{"id":"zoimN3cjB4OW"}},{"cell_type":"markdown","source":["- **`__init__`** function:\n","```python\n","    # TODO: Get all input parameters\n","    self.path_images = path_images\n","    self.labels = labels\n","    self.batch_size = batch_size\n","    self.n_classes = n_classes\n","    self.targe_size = target_size\n","    self.shuffle= shuffle\n","```\n","\n","- **`on_epoch_end`** function:\n","```python\n","    if self.shuffle:\n","    # TODO: Shuffle image paths and their labels together\n","      self.path_images, self.labels = shuffle(self.path_images, self.labels)\n","```\n","\n","- **`__get_image`** function:\n","```python\n","    # TODO: Read the image using OpenCV as the image format is JPG.\n","    #       Remember to include a dimension for the batches.\n","    x_sample = cv2.imread(path_image)    \n","    x_sample = cv2.resize(x_sample, (self.targe_size,self.targe_size))\n","    x_sample = np.expand_dims(x_sample, axis=0)\n","    x_sample = x_sample.astype(\"float\")\n","```\n","\n","- **`__get_label`** function:\n","```python\n","    # TODO: convert the label to categorical\n","    y_sample = to_categorical(label, num_classes=self.n_classes)\n","```\n","\n","- **`__getitem__`** function:\n","```python\n","    # TODO: initialize the two outputs of this function\n","    #       x: batch with images [batch_size, width, height, channels],\n","    #       y: batch with labels [batch_size, n_classes]\n","    x = np.zeros((current_batch_size,\n","                  self.targe_size,\n","                  self.targe_size,\n","                  3),\n","                  dtype=np.float32)\n","    \n","    y = np.zeros((current_batch_size,\n","                  self.n_classes),\n","                  dtype=np.float32)\n","    \n","    # TODO: Fill x and y with data from each image and its label\n","    for j, (path_image,label) in enumerate(zip(batch_images,batch_labels)):\n","        # Reading each image\n","        x_sample = self.__get_image(path_image)        \n","        # Get the label\n","        y_sample = self.__get_label(label)        \n","\n","        # Do not forget to normalize the data!\n","        x[j,...] = x_sample/255.0\n","        y[j,...] = y_sample\n","```"],"metadata":{"id":"_4Ooctll_UBM"}},{"cell_type":"markdown","source":["### In the file **`models.py`**"],"metadata":{"id":"NcOX6uowBlDq"}},{"cell_type":"markdown","source":["- **`create_cnn`** function:\n","```python\n","    # TODO: Add different layers to build a CNN: model.add(...)\n","    #       For this assignment, you can use the following layers:\n","    #       Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten,\n","    #       and Dense.\n","    #       Feel free to create your custom CNN using any of those layers.\n","\n","    model = Sequential()\n","    # Convolutional block 1\n","    model.add(Conv2D(filters[0],\n","                    (k,k),\n","                    input_shape=input_shape,\n","                    activation=\"relu\"))    \n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(2,2))  \n","    model.add(Dropout(rate=0.2))\n","    \n","    # More convolutional blocks\n","    for n in filters[1:]:\n","      model.add(Conv2D(n,\n","                      (k,k),\n","                      activation=\"relu\"))        \n","      model.add(BatchNormalization())\n","      model.add(MaxPooling2D(2,2))    \n","      model.add(Dropout(rate=0.2))\n","    \n","    # Flatten and output layer\n","    model.add(Flatten())\n","    model.add(Dense(100,\n","                    activation=\"relu\"))    \n","    # Output layer\n","    model.add(Dense(n_classes,\n","                    activation=\"softmax\"))\n","```"],"metadata":{"id":"F8QTL_LkB-Ul"}},{"cell_type":"markdown","metadata":{"id":"i3ammKZcRWqn"},"source":["# **Lab 04:** Vanilla **C**onvolutional **N**eural **N**etworks (CNN) for Image Classification"]},{"cell_type":"markdown","metadata":{"id":"hJj98oVxv8XK"},"source":["In this lab session, we will use the [UC Merced](http://weegee.vision.ucmerced.edu/datasets/landuse.html) dataset to cover the following topics:\n","- CNN for image classification\n","- Data generators with data augmentation\n","\n","This dataset has the following classes:\n","\n","<center>\n","\n","|Class| Description ||| Class | Description |\n","|:---:|:-----------:|||:-----:|:-----------:|\n","|  0  | agricultural|||  10   |    harbor   |\n","|  1  |  airplane   |||  11   |intersection |\n","|  2  |baseballdiamond|||12   |mediumresidential|\n","|  3  |   beach     |||  13   |mobilehomepark|\n","|  4  |  buildings  |||  14   |  overpass   |\n","|  5  |  chaparral  |||  15   | parkinglot  |\n","|  6  |denseresidential|||16  |    river    |\n","|  7  |    forest   |||  17   |   runway    |\n","|  8  |  freeway    |||  18   |sparseresidential|\n","|  9  | golfcourse  |||  19   | storagetanks|\n","|     |             |||  20   | tenniscourt |\n","\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"EyS5sA5SxSYe"},"source":["## **Mount Google Drive to Google Colab**"]},{"cell_type":"markdown","metadata":{"id":"hEtX6cij95Gp"},"source":["You can **skip** the following cells if you **do not want to storage** the trained model in your Google Drive."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21986,"status":"ok","timestamp":1715001313971,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"uZxaFpTRxUbn","outputId":"e6a5cb43-f91f-40e4-cdf8-8d9c7e931e12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"-E5rmPJkcVai"},"source":["Change **this path** to the **path of a folder** in your Google Drive to storage the files associated to this session (trained model, figures for visualization, etc.)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1715001316205,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"tjvyfvgVxVHb","outputId":"6b1647b6-ee4d-4886-a7be-0bed0eaa30ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colabs/DeepLearning_course/Lab_04\n"]}],"source":["# %cd drive/MyDrive/PATH/TO/YOUR/FOLDER\n","%cd drive/MyDrive/Colabs/DeepLearning_course/Lab_04"]},{"cell_type":"markdown","metadata":{"id":"ZcOA6hVa1PEE"},"source":["## **Load packages and data**"]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euW7Ud5AC5b5","executionInfo":{"status":"ok","timestamp":1715001356077,"user_tz":-120,"elapsed":10946,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"}},"outputId":"b1bf886a-efcd-4e34-b72e-0dc58b091d87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.1.1-py2.py3-none-any.whl (277 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.1.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"]}]},{"cell_type":"code","source":["!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4KekJRbC7Jt","executionInfo":{"status":"ok","timestamp":1715001407407,"user_tz":-120,"elapsed":38163,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"}},"outputId":"4c8f1f27-4ba9-409b-e076-c2e401eb85ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EC09utecuSt8"},"outputs":[],"source":["# Management of files\n","import os\n","from os.path import exists, join\n","\n","# Tensorflow and Keras\n","from tensorflow.keras.callbacks import ModelCheckpoint, \\\n","                                       EarlyStopping\n","\n","# Monitor training\n","import wandb\n","from wandb.keras import WandbMetricsLogger\n","\n","# Working with arrays\n","import numpy as np\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","\n","# External files with functions to load the dataset,\n","# create a CNN model, and a data generator.\n","from importlib import reload\n","import datasets\n","import models\n","import data_generator\n","# Useful to reload modified external files without need\n","# of restarting the kernel. Just run again this cell.\n","reload(datasets)\n","reload(models)\n","reload(data_generator)\n","\n","from datasets import *\n","from models import *\n","from data_generator import *"]},{"cell_type":"markdown","metadata":{"id":"pgp2I7Y0CIuK"},"source":["**Variables**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fg3h0LhMCKX3"},"outputs":[],"source":["PROJECT_DIR = \".\" # os.getcwd()\n","SEED = 42\n","BATCH_SIZE = 32\n","TARGET_SIZE = 256\n","EPOCHS = 200"]},{"cell_type":"markdown","metadata":{"id":"TkaArXxnKH8L"},"source":["### **Download the dataset**"]},{"cell_type":"markdown","metadata":{"id":"O8o62XH9CTHP"},"source":["First, we will download the data for this session from the given link.\n","\n","For this, we will use **`wget`** and **`zipfile`** packages to download the zip file **`data_satellite.zip`** and to extract its content.\n","\n","The function **`download_ucmerced`** is defined in the file **`datasets.py`**\n","\n","_In case of error during the download, you can download the dataset directly from [here](http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip)._"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QH0mmClSjOA"},"outputs":[],"source":["download_ucmerced(PROJECT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"5PFgRKW8KOcF"},"source":["### **Reading the dataset**"]},{"cell_type":"markdown","source":["The function **`read_ucmerced`** is defined in the file **`datasets.py`**"],"metadata":{"id":"oKJYIktySfz3"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":6959,"status":"ok","timestamp":1715001438895,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"j860qPxROcLH","outputId":"c489055b-16ba-4bf7-d808-8a0d337110f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             path_image          class_str  \\\n","0         ./UCMerced_LandUse/Images/harbor/harbor34.tif             harbor   \n","1     ./UCMerced_LandUse/Images/intersection/interse...       intersection   \n","2     ./UCMerced_LandUse/Images/agricultural/agricul...       agricultural   \n","3     ./UCMerced_LandUse/Images/mobilehomepark/mobil...     mobilehomepark   \n","4     ./UCMerced_LandUse/Images/denseresidential/den...   denseresidential   \n","...                                                 ...                ...   \n","2095        ./UCMerced_LandUse/Images/river/river38.tif              river   \n","2096      ./UCMerced_LandUse/Images/harbor/harbor95.tif             harbor   \n","2097  ./UCMerced_LandUse/Images/intersection/interse...       intersection   \n","2098  ./UCMerced_LandUse/Images/mediumresidential/me...  mediumresidential   \n","2099    ./UCMerced_LandUse/Images/freeway/freeway60.tif            freeway   \n","\n","      class_int  \n","0            10  \n","1            11  \n","2             0  \n","3            13  \n","4             6  \n","...         ...  \n","2095         16  \n","2096         10  \n","2097         11  \n","2098         12  \n","2099          8  \n","\n","[2100 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-7205b370-264f-434f-9305-2d49b88aab40\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path_image</th>\n","      <th>class_str</th>\n","      <th>class_int</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>./UCMerced_LandUse/Images/harbor/harbor34.tif</td>\n","      <td>harbor</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>./UCMerced_LandUse/Images/intersection/interse...</td>\n","      <td>intersection</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>./UCMerced_LandUse/Images/agricultural/agricul...</td>\n","      <td>agricultural</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>./UCMerced_LandUse/Images/mobilehomepark/mobil...</td>\n","      <td>mobilehomepark</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>./UCMerced_LandUse/Images/denseresidential/den...</td>\n","      <td>denseresidential</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2095</th>\n","      <td>./UCMerced_LandUse/Images/river/river38.tif</td>\n","      <td>river</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2096</th>\n","      <td>./UCMerced_LandUse/Images/harbor/harbor95.tif</td>\n","      <td>harbor</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2097</th>\n","      <td>./UCMerced_LandUse/Images/intersection/interse...</td>\n","      <td>intersection</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2098</th>\n","      <td>./UCMerced_LandUse/Images/mediumresidential/me...</td>\n","      <td>mediumresidential</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>2099</th>\n","      <td>./UCMerced_LandUse/Images/freeway/freeway60.tif</td>\n","      <td>freeway</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2100 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7205b370-264f-434f-9305-2d49b88aab40')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7205b370-264f-434f-9305-2d49b88aab40 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7205b370-264f-434f-9305-2d49b88aab40');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5140d89a-e16d-4b2b-930d-fefbe3569ba1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5140d89a-e16d-4b2b-930d-fefbe3569ba1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5140d89a-e16d-4b2b-930d-fefbe3569ba1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2100,\n  \"fields\": [\n    {\n      \"column\": \"path_image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2100,\n        \"samples\": [\n          \"./UCMerced_LandUse/Images/harbor/harbor06.tif\",\n          \"./UCMerced_LandUse/Images/harbor/harbor79.tif\",\n          \"./UCMerced_LandUse/Images/tenniscourt/tenniscourt35.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_str\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"harbor\",\n          \"baseballdiamond\",\n          \"tenniscourt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_int\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          10,\n          2,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["path_data = join(PROJECT_DIR, \"UCMerced_LandUse\", \"Images\")\n","\n","df, n_classes = read_ucmerced(path_data=path_data,\n","                              SEED=SEED)\n","classes = np.unique(df[\"class_str\"].values)\n","\n","df"]},{"cell_type":"markdown","metadata":{"id":"yYxjd9DIPVzG"},"source":["### **Train, Validation and Test sets**"]},{"cell_type":"markdown","metadata":{"id":"ER9UAoDjPbmA"},"source":["Now, we can create **three disjoint** sets: `train`, `validation` and `test`.\n","\n","Let's use the following proportions:\n","- `train`: 60%\n","- `validation`: 20%\n","- `test`: 20%\n","\n","The function **`train_val_test_split`** is defined in the file **`datasets.py`**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wh6ue_zUPYFe"},"outputs":[],"source":["splits = train_val_test_split(df,\n","                              val_size=0.2,\n","                              test_size=0.2,\n","                              SEED=SEED)\n","\n","x_train = splits[\"x_train\"]\n","y_train = splits[\"y_train\"]\n","x_val = splits[\"x_val\"]\n","y_val = splits[\"y_val\"]\n","x_test = splits[\"x_test\"]\n","y_test = splits[\"y_test\"]"]},{"cell_type":"markdown","metadata":{"id":"GWA3F7NRPFsY"},"source":["### **Class distribution**\n"]},{"cell_type":"markdown","metadata":{"id":"CzXid0d9PLf-"},"source":["For **sanity check**, let's verify the **class distribution** of each set: `train`, `validation` and `test`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715001450428,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"oqLxOEeaPGQX","outputId":"ba967a35-96d3-4cae-f562-e034be5869ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Samples per class - train: [60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60 60]\n","Samples per class - val: [20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20]\n","Samples per class - test: [20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20]\n"]}],"source":["# Number of samples per class\n","_, counts_train = np.unique(y_train, return_counts=True)\n","_, counts_val = np.unique(y_val, return_counts=True)\n","_, counts_test = np.unique(y_test, return_counts=True)\n","\n","print(\"Samples per class - train: {}\".format(counts_train))\n","print(\"Samples per class - val: {}\".format(counts_val))\n","print(\"Samples per class - test: {}\".format(counts_test))"]},{"cell_type":"markdown","metadata":{"id":"cxIMxNBkYpCD"},"source":["## **Data generator with data augmentation**"]},{"cell_type":"markdown","source":["There are many options to apply transformations to each sample in a dataset an increase the number of samples and their variability."],"metadata":{"id":"VwNwCj3iT_h_"}},{"cell_type":"markdown","source":["**1. [Keras ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)**\n","\n","```python\n","tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=0,\n","    brightness_range=None,    \n","    zoom_range=0.0,    \n","    fill_mode='nearest',    \n","    horizontal_flip=False,\n","    vertical_flip=False,\n",")\n","```\n"],"metadata":{"id":"YNY1tGjiTS3G"}},{"cell_type":"markdown","source":["**2. [Albumentations](https://github.com/albumentations-team/albumentations)**\n","\n","<center>\n","\n","**Pixel-level transformations**\n","\n","<img src=\"https://camo.githubusercontent.com/0a0cea2503f569ac965d9de888206b482d13ffe751c682638c730296a352e1ba/68747470733a2f2f686162726173746f726167652e6f72672f776562742f62642f6e652f72762f62646e6572763563746b75646d73617a6e687734637273646669772e6a706567\" width=800>\n","\n","**Semantic segmentation**\n","\n","<img src=\"https://camo.githubusercontent.com/d0235725dc1c4a25eee2d02e674f566d13e2d02fd940f52f500f06c9ae9e0797/68747470733a2f2f686162726173746f726167652e6f72672f776562742f73752f77612f6e702f737577616e70656f36777737777077746f6274727a645f636732302e6a706567\" width=800>\n","\n","**Object detection**\n","\n","<img src=\"https://camo.githubusercontent.com/d11f6965edd722d6d10c369665da745fb9d5423e596726e14ec1a0090bd4ee89/68747470733a2f2f686162726173746f726167652e6f72672f776562742f727a2f2d682f336a2f727a2d68336a616c62786963386f5f6668756378797374733474632e6a706567\" width=600>\n","\n","</center>"],"metadata":{"id":"V6GapVoATf1C"}},{"cell_type":"markdown","source":["**3. [scikit-image](https://scikit-image.org/)**\n","\n","**4. [Augmentor](https://augmentor.readthedocs.io/en/master/)**\n","\n","**5. [Torchvision](https://pytorch.org/vision/stable/index.html)**\n","\n","**6. [imgaug](https://imgaug.readthedocs.io/en/latest/)**\n","\n","**7. [OpenCV](https://opencv.org/)**"],"metadata":{"id":"-RyzUyNMTjfA"}},{"cell_type":"markdown","source":["### **Using albumentations**"],"metadata":{"id":"x1gaZcnGbuie"}},{"cell_type":"markdown","source":["You can check the documentation here: [Albumentations documentation](https://albumentations.ai/docs/)\n","\n","Each transformation has a parameter `p`, which is the probability of applying that transform.\n","\n","You can use the [Composition API](https://albumentations.ai/docs/api_reference/core/composition/) to combine transformations using the `Compose`, `OneOf`, `OneOrOther`, `SomeOf`, among others."],"metadata":{"id":"mgPEsJK9T1PI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCkYZmgsRB5H"},"outputs":[],"source":["from albumentations import Blur, \\\n","                           Compose, \\\n","                           HorizontalFlip, \\\n","                           RandomBrightnessContrast, \\\n","                           RandomRotate90, \\\n","                           VerticalFlip\n","\n","def augmentation():\n","    return Compose([HorizontalFlip(p=0.5),\n","                    VerticalFlip(p=0.5),\n","                    RandomRotate90(p=0.5),\n","                    Blur(p=0.01, blur_limit=3),\n","                    RandomBrightnessContrast(p=0.5),\n","                   ], p = 1)"]},{"cell_type":"markdown","source":["**How to select which transformation we should apply?**"],"metadata":{"id":"GQ9rVRcC2K_o"}},{"cell_type":"markdown","source":["Let's see the implementation of a data generator with data augmentation in the file **`data_generator.py`**."],"metadata":{"id":"0VB3ZzZucWEO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYEtY1ognL7w"},"outputs":[],"source":["data_gen_train = DataGenerator(path_images=x_train,\n","                               labels=y_train,\n","                               batch_size=BATCH_SIZE,\n","                               n_classes=n_classes,\n","                               target_size=TARGET_SIZE,\n","                               shuffle=True)\n","\n","data_gen_train_aug = DataGenerator(path_images=x_train,\n","                                   labels=y_train,\n","                                   batch_size=BATCH_SIZE,\n","                                   n_classes=n_classes,\n","                                   target_size=TARGET_SIZE,\n","                                   augmentation=augmentation,\n","                                   shuffle=True)\n","\n","data_gen_val = DataGenerator(path_images=x_val,\n","                             labels=y_val,\n","                             batch_size=BATCH_SIZE,\n","                             n_classes=n_classes,\n","                             target_size=TARGET_SIZE,\n","                             shuffle=False)"]},{"cell_type":"markdown","source":["For sanity check, you should always verify (data type, shape and visualization) the output of your data generators."],"metadata":{"id":"95I-fcULhYKJ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614,"output_embedded_package_id":"1jTBcacTF5Ela7wtu4BXtte-mZkdxF6mN"},"executionInfo":{"elapsed":4630,"status":"ok","timestamp":1715001545274,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"VFe-IwSiRbn9","outputId":"c3ee5c7f-7ea4-468e-85ca-22734642e8b0"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for data,data_aug in zip(data_gen_train, data_gen_train_aug):\n","  x = data[0]\n","  x_aug = data_aug[0]\n","\n","  plt.figure(figsize=(20,10))\n","  for j, (x_i,x_aug_i) in enumerate(zip(x,x_aug)):\n","    img = np.concatenate((x_i,np.zeros((256,10,3)),x_aug_i), axis=1)\n","    img = img*255\n","    img = img.astype(np.uint8)\n","\n","    plt.subplot(5,5,j+1)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    plt.title(\"Original   |   Augmented\")\n","    if j >= 24:\n","      break\n","  plt.show()\n","  break"]},{"cell_type":"markdown","metadata":{"id":"dah4bJlO-rOW"},"source":["## **CNN for image classification**\n"]},{"cell_type":"markdown","source":["Let's create a CNN architecture with the following parameters:\n","- Input shape: $256\\times 256\\times 3$\n","- Convolutional layers (Conv):\n","  - Kernel size ($k$): $3\\times 3$\n","  - Number of kernels: 16, 32, 64, 128 and 256\n","  - Padding: 0\n","  - Stride: 1\n","  - Activation: `ReLU`\n","- Convolutional blocks: `Conv + BatchNorm + MaxPool + Dropout`\n","- Number of convolutional blocks: 5\n","- Dense layers: `100, n_classes`\n"],"metadata":{"id":"QpNifmUpoTot"}},{"cell_type":"markdown","source":["This is a deep network with 5 convolutional layers. **How can we define the number of convolutional layers?**"],"metadata":{"id":"oupqqtXoqD9V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSjaGT2v-tQi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715001572339,"user_tz":-120,"elapsed":2248,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"}},"outputId":"b1f3968f-8f14-4f72-a5ba-9138edccc843"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 254, 254, 16)      448       \n","                                                                 \n"," batch_normalization (Batch  (None, 254, 254, 16)      64        \n"," Normalization)                                                  \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 127, 127, 16)      0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 125, 125, 32)      128       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 62, 62, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 60, 60, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 30, 30, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 30, 30, 64)        0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 28, 28, 128)       73856     \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 28, 28, 128)       512       \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 14, 14, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_3 (Dropout)         (None, 14, 14, 128)       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 12, 12, 256)       295168    \n","                                                                 \n"," batch_normalization_4 (Bat  (None, 12, 12, 256)       1024      \n"," chNormalization)                                                \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 6, 6, 256)         0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_4 (Dropout)         (None, 6, 6, 256)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 9216)              0         \n","                                                                 \n"," dense (Dense)               (None, 100)               921700    \n","                                                                 \n"," dense_1 (Dense)             (None, 21)                2121      \n","                                                                 \n","=================================================================\n","Total params: 1318413 (5.03 MB)\n","Trainable params: 1317421 (5.03 MB)\n","Non-trainable params: 992 (3.88 KB)\n","_________________________________________________________________\n"]}],"source":["filters = [16, 32, 64, 128, 256]\n","k = 3\n","\n","model_orig = create_cnn(filters=filters,\n","                        k=k,\n","                        input_shape=(TARGET_SIZE,TARGET_SIZE,3),\n","                        n_classes=n_classes)\n","model_aug = create_cnn(filters=filters,\n","                       k=k,\n","                       input_shape=(TARGET_SIZE,TARGET_SIZE,3),\n","                       n_classes=n_classes)\n","\n","model_orig.summary()"]},{"cell_type":"markdown","metadata":{"id":"oXjo2eGu1QHk"},"source":["## **Training without data augmentation**\n"]},{"cell_type":"code","source":["def get_ckpt(ckpt_name):\n","    return ModelCheckpoint(ckpt_name,\n","                           mode=\"max\",\n","                           save_best_only=True,\n","                           monitor=\"val_accuracy\",\n","                           verbose=1)"],"metadata":{"id":"8N96TaoiWb7C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Callbacks**"],"metadata":{"id":"ks62-iBc8pzs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgBvpPOz_kI8","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1715001658670,"user_tz":-120,"elapsed":12709,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"}},"outputId":"fe325c4e-ff42-4e50-955e-e8aed07102ed"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpedro9589\u001b[0m (\u001b[33migp-tubs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/Colabs/DeepLearning_course/Lab_04/wandb/run-20240506_132052-ktmfmmw8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/ktmfmmw8' target=\"_blank\">vanilla-cnn-orig-classification-ucmerced</a></strong> to <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/ktmfmmw8' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/ktmfmmw8</a>"]},"metadata":{}}],"source":["# Callbacks\n","\n","# Checkpoints\n","cb_autosave_orig = get_ckpt(\"cnn_orig.h5\")\n","\n","# Early stopping\n","cb_early_stop = EarlyStopping(patience=20,\n","                           verbose=1,\n","                           mode=\"auto\",\n","                           monitor=\"val_accuracy\")\n","\n","# start a new wandb run to track this script\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"Vanilla CNN for image classification with UCMerced\",\n","    name=\"vanilla-cnn-orig-classification-ucmerced\",\n","\n","    # track hyperparameters and run metadata\n","    config={\n","    \"architecture\": \"Vanilla CNN\",\n","    \"dataset\": \"UCMerced\",\n","    \"bs\": BATCH_SIZE\n","    }\n",")\n","\n","cb_wandb_orig = WandbMetricsLogger()\n","\n","cb_orig = [cb_autosave_orig, cb_early_stop, cb_wandb_orig]"]},{"cell_type":"markdown","metadata":{"id":"GpN8IibKyV8x"},"source":["### **Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e568754905394a3f9d4cf4a3b0c49b56","e3c81037cf02449593a3779d0d1cd6ad","676f87eeb9e24d96a29c0e9502d13f1e","a22411c5481f4073ab520e8f70aa2ac3","3a89d50453b247dda47b9cf248b6899f","b5056a769c5644db9eac4652c31f9ead","95a97c0609d34ee08740a38a9f29e6fb","c7987b2db48f406aa72ac4231736c364"]},"executionInfo":{"elapsed":981376,"status":"ok","timestamp":1715002657250,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"NIaFw0zRtFNl","outputId":"e0cfc7aa-b1da-4117-f06e-ac60255ab81b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","40/40 [==============================] - ETA: 0s - loss: 3.4589 - accuracy: 0.1587\n","Epoch 1: val_accuracy improved from -inf to 0.04762, saving model to cnn_orig.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 463s 11s/step - loss: 3.4589 - accuracy: 0.1587 - val_loss: 4.3183 - val_accuracy: 0.0476\n","Epoch 2/200\n","40/40 [==============================] - ETA: 0s - loss: 2.2274 - accuracy: 0.3278\n","Epoch 2: val_accuracy improved from 0.04762 to 0.05714, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 255ms/step - loss: 2.2274 - accuracy: 0.3278 - val_loss: 7.4445 - val_accuracy: 0.0571\n","Epoch 3/200\n","40/40 [==============================] - ETA: 0s - loss: 1.7880 - accuracy: 0.4762\n","Epoch 3: val_accuracy did not improve from 0.05714\n","40/40 [==============================] - 9s 233ms/step - loss: 1.7880 - accuracy: 0.4762 - val_loss: 8.4369 - val_accuracy: 0.0476\n","Epoch 4/200\n","40/40 [==============================] - ETA: 0s - loss: 1.4367 - accuracy: 0.5730\n","Epoch 4: val_accuracy improved from 0.05714 to 0.06190, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 245ms/step - loss: 1.4367 - accuracy: 0.5730 - val_loss: 10.2921 - val_accuracy: 0.0619\n","Epoch 5/200\n","40/40 [==============================] - ETA: 0s - loss: 1.0735 - accuracy: 0.6706\n","Epoch 5: val_accuracy improved from 0.06190 to 0.07381, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 239ms/step - loss: 1.0735 - accuracy: 0.6706 - val_loss: 10.7118 - val_accuracy: 0.0738\n","Epoch 6/200\n","40/40 [==============================] - ETA: 0s - loss: 0.8535 - accuracy: 0.7325\n","Epoch 6: val_accuracy did not improve from 0.07381\n","40/40 [==============================] - 10s 240ms/step - loss: 0.8535 - accuracy: 0.7325 - val_loss: 15.3203 - val_accuracy: 0.0476\n","Epoch 7/200\n","40/40 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.7817\n","Epoch 7: val_accuracy improved from 0.07381 to 0.09762, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 241ms/step - loss: 0.6929 - accuracy: 0.7817 - val_loss: 11.7605 - val_accuracy: 0.0976\n","Epoch 8/200\n","40/40 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.8437\n","Epoch 8: val_accuracy did not improve from 0.09762\n","40/40 [==============================] - 10s 242ms/step - loss: 0.5164 - accuracy: 0.8437 - val_loss: 8.4242 - val_accuracy: 0.0929\n","Epoch 9/200\n","40/40 [==============================] - ETA: 0s - loss: 0.4516 - accuracy: 0.8619\n","Epoch 9: val_accuracy improved from 0.09762 to 0.13333, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 256ms/step - loss: 0.4516 - accuracy: 0.8619 - val_loss: 10.8468 - val_accuracy: 0.1333\n","Epoch 10/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9056\n","Epoch 10: val_accuracy did not improve from 0.13333\n","40/40 [==============================] - 10s 242ms/step - loss: 0.2799 - accuracy: 0.9056 - val_loss: 8.9823 - val_accuracy: 0.0905\n","Epoch 11/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9444\n","Epoch 11: val_accuracy improved from 0.13333 to 0.18095, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 245ms/step - loss: 0.1680 - accuracy: 0.9444 - val_loss: 6.9440 - val_accuracy: 0.1810\n","Epoch 12/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9452\n","Epoch 12: val_accuracy improved from 0.18095 to 0.22619, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 244ms/step - loss: 0.1596 - accuracy: 0.9452 - val_loss: 6.2356 - val_accuracy: 0.2262\n","Epoch 13/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9611\n","Epoch 13: val_accuracy did not improve from 0.22619\n","40/40 [==============================] - 10s 252ms/step - loss: 0.1284 - accuracy: 0.9611 - val_loss: 6.5540 - val_accuracy: 0.2095\n","Epoch 14/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9786\n","Epoch 14: val_accuracy improved from 0.22619 to 0.25238, saving model to cnn_orig.h5\n","40/40 [==============================] - 11s 265ms/step - loss: 0.0602 - accuracy: 0.9786 - val_loss: 5.2693 - val_accuracy: 0.2524\n","Epoch 15/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9563\n","Epoch 15: val_accuracy improved from 0.25238 to 0.40238, saving model to cnn_orig.h5\n","40/40 [==============================] - 9s 235ms/step - loss: 0.1331 - accuracy: 0.9563 - val_loss: 3.5147 - val_accuracy: 0.4024\n","Epoch 16/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9540\n","Epoch 16: val_accuracy did not improve from 0.40238\n","40/40 [==============================] - 10s 241ms/step - loss: 0.1757 - accuracy: 0.9540 - val_loss: 4.0562 - val_accuracy: 0.3452\n","Epoch 17/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9667\n","Epoch 17: val_accuracy improved from 0.40238 to 0.51429, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 245ms/step - loss: 0.0967 - accuracy: 0.9667 - val_loss: 2.5898 - val_accuracy: 0.5143\n","Epoch 18/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9746\n","Epoch 18: val_accuracy improved from 0.51429 to 0.55476, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 246ms/step - loss: 0.0787 - accuracy: 0.9746 - val_loss: 3.0665 - val_accuracy: 0.5548\n","Epoch 19/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9524\n","Epoch 19: val_accuracy improved from 0.55476 to 0.60476, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 237ms/step - loss: 0.1771 - accuracy: 0.9524 - val_loss: 2.1444 - val_accuracy: 0.6048\n","Epoch 20/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9587\n","Epoch 20: val_accuracy did not improve from 0.60476\n","40/40 [==============================] - 10s 246ms/step - loss: 0.1504 - accuracy: 0.9587 - val_loss: 2.5427 - val_accuracy: 0.5524\n","Epoch 21/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.9603\n","Epoch 21: val_accuracy improved from 0.60476 to 0.62381, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 247ms/step - loss: 0.1250 - accuracy: 0.9603 - val_loss: 2.0658 - val_accuracy: 0.6238\n","Epoch 22/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9770\n","Epoch 22: val_accuracy did not improve from 0.62381\n","40/40 [==============================] - 9s 223ms/step - loss: 0.0576 - accuracy: 0.9770 - val_loss: 3.1864 - val_accuracy: 0.5571\n","Epoch 23/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9833\n","Epoch 23: val_accuracy did not improve from 0.62381\n","40/40 [==============================] - 9s 235ms/step - loss: 0.0567 - accuracy: 0.9833 - val_loss: 2.1689 - val_accuracy: 0.6095\n","Epoch 24/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9913\n","Epoch 24: val_accuracy did not improve from 0.62381\n","40/40 [==============================] - 10s 241ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 2.2103 - val_accuracy: 0.6071\n","Epoch 25/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9881\n","Epoch 25: val_accuracy did not improve from 0.62381\n","40/40 [==============================] - 9s 233ms/step - loss: 0.0315 - accuracy: 0.9881 - val_loss: 2.2945 - val_accuracy: 0.6024\n","Epoch 26/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9857\n","Epoch 26: val_accuracy improved from 0.62381 to 0.63095, saving model to cnn_orig.h5\n","40/40 [==============================] - 10s 239ms/step - loss: 0.0500 - accuracy: 0.9857 - val_loss: 2.0227 - val_accuracy: 0.6310\n","Epoch 27/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.9841\n","Epoch 27: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 236ms/step - loss: 0.0507 - accuracy: 0.9841 - val_loss: 3.3311 - val_accuracy: 0.4952\n","Epoch 28/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9413\n","Epoch 28: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 239ms/step - loss: 0.1730 - accuracy: 0.9413 - val_loss: 2.5872 - val_accuracy: 0.5810\n","Epoch 29/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.9524\n","Epoch 29: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 229ms/step - loss: 0.1809 - accuracy: 0.9524 - val_loss: 4.5943 - val_accuracy: 0.3952\n","Epoch 30/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9595\n","Epoch 30: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 219ms/step - loss: 0.1342 - accuracy: 0.9595 - val_loss: 3.1943 - val_accuracy: 0.4952\n","Epoch 31/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9556\n","Epoch 31: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 12s 308ms/step - loss: 0.1555 - accuracy: 0.9556 - val_loss: 3.6981 - val_accuracy: 0.4690\n","Epoch 32/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9690\n","Epoch 32: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 248ms/step - loss: 0.1174 - accuracy: 0.9690 - val_loss: 5.8546 - val_accuracy: 0.4405\n","Epoch 33/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9587\n","Epoch 33: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 235ms/step - loss: 0.1497 - accuracy: 0.9587 - val_loss: 3.2750 - val_accuracy: 0.5333\n","Epoch 34/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9746\n","Epoch 34: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 223ms/step - loss: 0.0914 - accuracy: 0.9746 - val_loss: 3.2945 - val_accuracy: 0.5643\n","Epoch 35/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9722\n","Epoch 35: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 232ms/step - loss: 0.0786 - accuracy: 0.9722 - val_loss: 2.8120 - val_accuracy: 0.5857\n","Epoch 36/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9857\n","Epoch 36: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 239ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 2.4984 - val_accuracy: 0.6000\n","Epoch 37/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9865\n","Epoch 37: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 235ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 2.4966 - val_accuracy: 0.6119\n","Epoch 38/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9944\n","Epoch 38: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 219ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 3.1069 - val_accuracy: 0.6024\n","Epoch 39/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9881\n","Epoch 39: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 240ms/step - loss: 0.0512 - accuracy: 0.9881 - val_loss: 5.0318 - val_accuracy: 0.4857\n","Epoch 40/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.9786\n","Epoch 40: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 239ms/step - loss: 0.0629 - accuracy: 0.9786 - val_loss: 2.9315 - val_accuracy: 0.5738\n","Epoch 41/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9921\n","Epoch 41: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 232ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 2.6990 - val_accuracy: 0.6071\n","Epoch 42/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.9833\n","Epoch 42: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 229ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 2.9628 - val_accuracy: 0.5714\n","Epoch 43/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9889\n","Epoch 43: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 243ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 2.9330 - val_accuracy: 0.6190\n","Epoch 44/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9905\n","Epoch 44: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 10s 238ms/step - loss: 0.0382 - accuracy: 0.9905 - val_loss: 2.8335 - val_accuracy: 0.6143\n","Epoch 45/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9762\n","Epoch 45: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 225ms/step - loss: 0.0916 - accuracy: 0.9762 - val_loss: 5.0268 - val_accuracy: 0.4429\n","Epoch 46/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9738\n","Epoch 46: val_accuracy did not improve from 0.63095\n","40/40 [==============================] - 9s 236ms/step - loss: 0.0955 - accuracy: 0.9738 - val_loss: 4.6400 - val_accuracy: 0.5119\n","Epoch 46: early stopping\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e568754905394a3f9d4cf4a3b0c49b56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▄▄▅▆▆▇▇███████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▅▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▁▁▂▂▂▃▃▃▃▅▇▇█▇█▇███▆▇▅▆▆▇▇▇██▆▇█▇██▆</td></tr><tr><td>epoch/val_loss</td><td>▂▄▄▅▆█▆▆▅▄▃▃▃▂▁▂▁▁▁▂▁▁▁▂▁▂▂▃▂▂▁▁▁▃▁▁▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.97381</td></tr><tr><td>epoch/epoch</td><td>45</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.09554</td></tr><tr><td>epoch/val_accuracy</td><td>0.5119</td></tr><tr><td>epoch/val_loss</td><td>4.63995</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">vanilla-cnn-orig-classification-ucmerced</strong> at: <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/ktmfmmw8' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/ktmfmmw8</a><br/> View project at: <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240506_132052-ktmfmmw8/logs</code>"]},"metadata":{}}],"source":["history_orig = model_orig.fit(data_gen_train,\n","                              epochs=EPOCHS,\n","                              validation_data=data_gen_val,\n","                              callbacks=cb_orig\n","                              )\n","wandb.finish()"]},{"cell_type":"markdown","source":["## **Training with data augmentation**"],"metadata":{"id":"jg69GdoD93Yd"}},{"cell_type":"markdown","source":["### **Callbacks**"],"metadata":{"id":"ZIZoBFZj-Wcf"}},{"cell_type":"code","source":["# Callbacks\n","\n","# Checkpoints\n","cb_autosave_aug = get_ckpt(\"cnn_aug.h5\")\n","\n","# Early stopping\n","cb_early_stop = EarlyStopping(patience=20,\n","                           verbose=1,\n","                           mode=\"auto\",\n","                           monitor=\"val_accuracy\")\n","\n","# start a new wandb run to track this script\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"Vanilla CNN for image classification with UCMerced\",\n","    name=\"vanilla-cnn-aug-classification-ucmerced\",\n","\n","    # track hyperparameters and run metadata\n","    config={\n","    \"architecture\": \"Vanilla CNN\",\n","    \"dataset\": \"UCMerced\",\n","    \"bs\": BATCH_SIZE\n","    }\n",")\n","\n","cb_wandb_aug = WandbMetricsLogger()\n","\n","cb_aug = [cb_autosave_aug, cb_early_stop, cb_wandb_aug]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"myb5IgLu8w-p","executionInfo":{"status":"ok","timestamp":1715002668501,"user_tz":-120,"elapsed":6048,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"}},"outputId":"153b5d9a-c0f0-4e15-e850-457de0129dea"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.6"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/Colabs/DeepLearning_course/Lab_04/wandb/run-20240506_133742-zefz29q8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/zefz29q8' target=\"_blank\">vanilla-cnn-aug-classification-ucmerced</a></strong> to <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/zefz29q8' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/zefz29q8</a>"]},"metadata":{}}]},{"cell_type":"markdown","source":["### **Training**"],"metadata":{"id":"kHjnjcKM-ZS2"}},{"cell_type":"code","source":["history_aug = model_aug.fit(data_gen_train_aug,\n","                            epochs=EPOCHS,\n","                            validation_data=data_gen_val,\n","                            callbacks=cb_aug\n","                            )\n","\n","wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["9b1753df0dff42e2b5ec66a7a4a0e885","e2e17267b1a84e94a667ee9a732e73a1","2e54f439244c4ed9a2dc850030bb90d6","689e9057a2ee43579d39fa7b6dc5c2c4","b8659f9acacd4b0eb43b13427419ffed","1fb9a6f772d74b629bdd7a2a69794dbb","894d501224604081b3ffceec3a160976","306d232f0f6e4c2dae42584f1728f056"]},"id":"8PH2X01lYIRZ","executionInfo":{"status":"ok","timestamp":1715004096122,"user_tz":-120,"elapsed":1421355,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"}},"outputId":"66713910-e82b-4d18-ed9c-1a6f8483ccca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","40/40 [==============================] - ETA: 0s - loss: 3.3278 - accuracy: 0.1437\n","Epoch 1: val_accuracy improved from -inf to 0.04762, saving model to cnn_aug.h5\n","40/40 [==============================] - 16s 299ms/step - loss: 3.3278 - accuracy: 0.1437 - val_loss: 6.7983 - val_accuracy: 0.0476\n","Epoch 2/200\n","40/40 [==============================] - ETA: 0s - loss: 2.7069 - accuracy: 0.1786\n","Epoch 2: val_accuracy did not improve from 0.04762\n","40/40 [==============================] - 10s 240ms/step - loss: 2.7069 - accuracy: 0.1786 - val_loss: 14.0544 - val_accuracy: 0.0476\n","Epoch 3/200\n","40/40 [==============================] - ETA: 0s - loss: 2.4849 - accuracy: 0.2405\n","Epoch 3: val_accuracy did not improve from 0.04762\n","40/40 [==============================] - 10s 253ms/step - loss: 2.4849 - accuracy: 0.2405 - val_loss: 10.4133 - val_accuracy: 0.0476\n","Epoch 4/200\n","40/40 [==============================] - ETA: 0s - loss: 2.2728 - accuracy: 0.3040\n","Epoch 4: val_accuracy did not improve from 0.04762\n","40/40 [==============================] - 10s 250ms/step - loss: 2.2728 - accuracy: 0.3040 - val_loss: 9.5473 - val_accuracy: 0.0476\n","Epoch 5/200\n","40/40 [==============================] - ETA: 0s - loss: 2.1962 - accuracy: 0.3183\n","Epoch 5: val_accuracy did not improve from 0.04762\n","40/40 [==============================] - 10s 252ms/step - loss: 2.1962 - accuracy: 0.3183 - val_loss: 12.4660 - val_accuracy: 0.0476\n","Epoch 6/200\n","40/40 [==============================] - ETA: 0s - loss: 1.9270 - accuracy: 0.3944\n","Epoch 6: val_accuracy improved from 0.04762 to 0.08333, saving model to cnn_aug.h5\n","40/40 [==============================] - 10s 258ms/step - loss: 1.9270 - accuracy: 0.3944 - val_loss: 8.0515 - val_accuracy: 0.0833\n","Epoch 7/200\n","40/40 [==============================] - ETA: 0s - loss: 1.7522 - accuracy: 0.4556\n","Epoch 7: val_accuracy did not improve from 0.08333\n","40/40 [==============================] - 11s 271ms/step - loss: 1.7522 - accuracy: 0.4556 - val_loss: 12.6672 - val_accuracy: 0.0643\n","Epoch 8/200\n","40/40 [==============================] - ETA: 0s - loss: 1.6230 - accuracy: 0.5024\n","Epoch 8: val_accuracy improved from 0.08333 to 0.12857, saving model to cnn_aug.h5\n","40/40 [==============================] - 10s 257ms/step - loss: 1.6230 - accuracy: 0.5024 - val_loss: 6.7189 - val_accuracy: 0.1286\n","Epoch 9/200\n","40/40 [==============================] - ETA: 0s - loss: 1.4886 - accuracy: 0.5206\n","Epoch 9: val_accuracy did not improve from 0.12857\n","40/40 [==============================] - 10s 254ms/step - loss: 1.4886 - accuracy: 0.5206 - val_loss: 15.6873 - val_accuracy: 0.0500\n","Epoch 10/200\n","40/40 [==============================] - ETA: 0s - loss: 1.3129 - accuracy: 0.5810\n","Epoch 10: val_accuracy did not improve from 0.12857\n","40/40 [==============================] - 10s 256ms/step - loss: 1.3129 - accuracy: 0.5810 - val_loss: 5.8649 - val_accuracy: 0.0929\n","Epoch 11/200\n","40/40 [==============================] - ETA: 0s - loss: 1.2112 - accuracy: 0.6190\n","Epoch 11: val_accuracy did not improve from 0.12857\n","40/40 [==============================] - 10s 254ms/step - loss: 1.2112 - accuracy: 0.6190 - val_loss: 5.0796 - val_accuracy: 0.1190\n","Epoch 12/200\n","40/40 [==============================] - ETA: 0s - loss: 1.1467 - accuracy: 0.6381\n","Epoch 12: val_accuracy improved from 0.12857 to 0.21667, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 277ms/step - loss: 1.1467 - accuracy: 0.6381 - val_loss: 4.6734 - val_accuracy: 0.2167\n","Epoch 13/200\n","40/40 [==============================] - ETA: 0s - loss: 1.0242 - accuracy: 0.6437\n","Epoch 13: val_accuracy improved from 0.21667 to 0.39048, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 277ms/step - loss: 1.0242 - accuracy: 0.6437 - val_loss: 2.5559 - val_accuracy: 0.3905\n","Epoch 14/200\n","40/40 [==============================] - ETA: 0s - loss: 0.9862 - accuracy: 0.6857\n","Epoch 14: val_accuracy improved from 0.39048 to 0.43571, saving model to cnn_aug.h5\n","40/40 [==============================] - 10s 260ms/step - loss: 0.9862 - accuracy: 0.6857 - val_loss: 2.3579 - val_accuracy: 0.4357\n","Epoch 15/200\n","40/40 [==============================] - ETA: 0s - loss: 0.8647 - accuracy: 0.7183\n","Epoch 15: val_accuracy improved from 0.43571 to 0.46190, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 272ms/step - loss: 0.8647 - accuracy: 0.7183 - val_loss: 2.3100 - val_accuracy: 0.4619\n","Epoch 16/200\n","40/40 [==============================] - ETA: 0s - loss: 0.8847 - accuracy: 0.7024\n","Epoch 16: val_accuracy improved from 0.46190 to 0.48095, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 272ms/step - loss: 0.8847 - accuracy: 0.7024 - val_loss: 2.3244 - val_accuracy: 0.4810\n","Epoch 17/200\n","40/40 [==============================] - ETA: 0s - loss: 0.8143 - accuracy: 0.7230\n","Epoch 17: val_accuracy did not improve from 0.48095\n","40/40 [==============================] - 10s 236ms/step - loss: 0.8143 - accuracy: 0.7230 - val_loss: 2.6731 - val_accuracy: 0.4714\n","Epoch 18/200\n","40/40 [==============================] - ETA: 0s - loss: 0.7549 - accuracy: 0.7405\n","Epoch 18: val_accuracy improved from 0.48095 to 0.57857, saving model to cnn_aug.h5\n","40/40 [==============================] - 12s 299ms/step - loss: 0.7549 - accuracy: 0.7405 - val_loss: 1.8215 - val_accuracy: 0.5786\n","Epoch 19/200\n","40/40 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.7571\n","Epoch 19: val_accuracy improved from 0.57857 to 0.61429, saving model to cnn_aug.h5\n","40/40 [==============================] - 15s 365ms/step - loss: 0.7314 - accuracy: 0.7571 - val_loss: 1.3314 - val_accuracy: 0.6143\n","Epoch 20/200\n","40/40 [==============================] - ETA: 0s - loss: 0.6879 - accuracy: 0.7770\n","Epoch 20: val_accuracy improved from 0.61429 to 0.64048, saving model to cnn_aug.h5\n","40/40 [==============================] - 10s 259ms/step - loss: 0.6879 - accuracy: 0.7770 - val_loss: 1.3415 - val_accuracy: 0.6405\n","Epoch 21/200\n","40/40 [==============================] - ETA: 0s - loss: 0.6568 - accuracy: 0.7825\n","Epoch 21: val_accuracy improved from 0.64048 to 0.66190, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 263ms/step - loss: 0.6568 - accuracy: 0.7825 - val_loss: 1.1193 - val_accuracy: 0.6619\n","Epoch 22/200\n","40/40 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.8016\n","Epoch 22: val_accuracy did not improve from 0.66190\n","40/40 [==============================] - 12s 292ms/step - loss: 0.5896 - accuracy: 0.8016 - val_loss: 1.8463 - val_accuracy: 0.5429\n","Epoch 23/200\n","40/40 [==============================] - ETA: 0s - loss: 0.5903 - accuracy: 0.7794\n","Epoch 23: val_accuracy did not improve from 0.66190\n","40/40 [==============================] - 10s 258ms/step - loss: 0.5903 - accuracy: 0.7794 - val_loss: 2.2064 - val_accuracy: 0.5286\n","Epoch 24/200\n","40/40 [==============================] - ETA: 0s - loss: 0.5157 - accuracy: 0.8198\n","Epoch 24: val_accuracy did not improve from 0.66190\n","40/40 [==============================] - 10s 245ms/step - loss: 0.5157 - accuracy: 0.8198 - val_loss: 1.5919 - val_accuracy: 0.6024\n","Epoch 25/200\n","40/40 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.8373\n","Epoch 25: val_accuracy did not improve from 0.66190\n","40/40 [==============================] - 10s 243ms/step - loss: 0.4935 - accuracy: 0.8373 - val_loss: 1.3139 - val_accuracy: 0.6595\n","Epoch 26/200\n","39/40 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8550\n","Epoch 26: val_accuracy did not improve from 0.66190\n","40/40 [==============================] - 11s 264ms/step - loss: 0.4480 - accuracy: 0.8563 - val_loss: 1.9700 - val_accuracy: 0.5310\n","Epoch 27/200\n","40/40 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.8333\n","Epoch 27: val_accuracy did not improve from 0.66190\n","40/40 [==============================] - 11s 264ms/step - loss: 0.5257 - accuracy: 0.8333 - val_loss: 2.2555 - val_accuracy: 0.5071\n","Epoch 28/200\n","40/40 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8540\n","Epoch 28: val_accuracy improved from 0.66190 to 0.66429, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 269ms/step - loss: 0.4255 - accuracy: 0.8540 - val_loss: 1.1540 - val_accuracy: 0.6643\n","Epoch 29/200\n","40/40 [==============================] - ETA: 0s - loss: 0.4662 - accuracy: 0.8587\n","Epoch 29: val_accuracy did not improve from 0.66429\n","40/40 [==============================] - 10s 252ms/step - loss: 0.4662 - accuracy: 0.8587 - val_loss: 1.5054 - val_accuracy: 0.6452\n","Epoch 30/200\n","40/40 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8635\n","Epoch 30: val_accuracy did not improve from 0.66429\n","40/40 [==============================] - 10s 255ms/step - loss: 0.4243 - accuracy: 0.8635 - val_loss: 1.7145 - val_accuracy: 0.5881\n","Epoch 31/200\n","40/40 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8794\n","Epoch 31: val_accuracy improved from 0.66429 to 0.66905, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 286ms/step - loss: 0.3536 - accuracy: 0.8794 - val_loss: 1.4499 - val_accuracy: 0.6690\n","Epoch 32/200\n","40/40 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8587\n","Epoch 32: val_accuracy improved from 0.66905 to 0.74762, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 269ms/step - loss: 0.4261 - accuracy: 0.8587 - val_loss: 0.9884 - val_accuracy: 0.7476\n","Epoch 33/200\n","40/40 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.8690\n","Epoch 33: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 253ms/step - loss: 0.3618 - accuracy: 0.8690 - val_loss: 1.2820 - val_accuracy: 0.6762\n","Epoch 34/200\n","40/40 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.8937\n","Epoch 34: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 252ms/step - loss: 0.3218 - accuracy: 0.8937 - val_loss: 4.1347 - val_accuracy: 0.4024\n","Epoch 35/200\n","40/40 [==============================] - ETA: 0s - loss: 0.3831 - accuracy: 0.8802\n","Epoch 35: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 260ms/step - loss: 0.3831 - accuracy: 0.8802 - val_loss: 1.2019 - val_accuracy: 0.7357\n","Epoch 36/200\n","40/40 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8841\n","Epoch 36: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 254ms/step - loss: 0.3312 - accuracy: 0.8841 - val_loss: 1.4050 - val_accuracy: 0.7048\n","Epoch 37/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.9032\n","Epoch 37: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 248ms/step - loss: 0.2858 - accuracy: 0.9032 - val_loss: 1.1118 - val_accuracy: 0.7214\n","Epoch 38/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.9175\n","Epoch 38: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 246ms/step - loss: 0.2572 - accuracy: 0.9175 - val_loss: 1.0624 - val_accuracy: 0.7476\n","Epoch 39/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9167\n","Epoch 39: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 11s 267ms/step - loss: 0.2685 - accuracy: 0.9167 - val_loss: 1.1805 - val_accuracy: 0.7286\n","Epoch 40/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.9135\n","Epoch 40: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 11s 262ms/step - loss: 0.2557 - accuracy: 0.9135 - val_loss: 1.2808 - val_accuracy: 0.6857\n","Epoch 41/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.9119\n","Epoch 41: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 258ms/step - loss: 0.2799 - accuracy: 0.9119 - val_loss: 1.3208 - val_accuracy: 0.7238\n","Epoch 42/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9198\n","Epoch 42: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 258ms/step - loss: 0.2312 - accuracy: 0.9198 - val_loss: 1.3719 - val_accuracy: 0.6952\n","Epoch 43/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9135\n","Epoch 43: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 10s 254ms/step - loss: 0.2401 - accuracy: 0.9135 - val_loss: 1.5269 - val_accuracy: 0.6810\n","Epoch 44/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9317\n","Epoch 44: val_accuracy did not improve from 0.74762\n","40/40 [==============================] - 11s 262ms/step - loss: 0.2185 - accuracy: 0.9317 - val_loss: 1.2175 - val_accuracy: 0.7071\n","Epoch 45/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9214\n","Epoch 45: val_accuracy improved from 0.74762 to 0.76190, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 275ms/step - loss: 0.2503 - accuracy: 0.9214 - val_loss: 1.0008 - val_accuracy: 0.7619\n","Epoch 46/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9286\n","Epoch 46: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 12s 289ms/step - loss: 0.2082 - accuracy: 0.9286 - val_loss: 1.0911 - val_accuracy: 0.7452\n","Epoch 47/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.9151\n","Epoch 47: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 10s 245ms/step - loss: 0.2528 - accuracy: 0.9151 - val_loss: 1.5894 - val_accuracy: 0.6190\n","Epoch 48/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.9310\n","Epoch 48: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 11s 262ms/step - loss: 0.2370 - accuracy: 0.9310 - val_loss: 1.4296 - val_accuracy: 0.6714\n","Epoch 49/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9254\n","Epoch 49: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 11s 263ms/step - loss: 0.2482 - accuracy: 0.9254 - val_loss: 1.1656 - val_accuracy: 0.7429\n","Epoch 50/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.9246\n","Epoch 50: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 10s 256ms/step - loss: 0.2198 - accuracy: 0.9246 - val_loss: 1.1025 - val_accuracy: 0.7571\n","Epoch 51/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9317\n","Epoch 51: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 10s 247ms/step - loss: 0.2119 - accuracy: 0.9317 - val_loss: 1.8527 - val_accuracy: 0.6452\n","Epoch 52/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.9302\n","Epoch 52: val_accuracy did not improve from 0.76190\n","40/40 [==============================] - 10s 257ms/step - loss: 0.2186 - accuracy: 0.9302 - val_loss: 1.1536 - val_accuracy: 0.7286\n","Epoch 53/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9222\n","Epoch 53: val_accuracy improved from 0.76190 to 0.76905, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 280ms/step - loss: 0.2154 - accuracy: 0.9222 - val_loss: 1.0220 - val_accuracy: 0.7690\n","Epoch 54/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9429\n","Epoch 54: val_accuracy did not improve from 0.76905\n","40/40 [==============================] - 11s 262ms/step - loss: 0.1637 - accuracy: 0.9429 - val_loss: 1.0647 - val_accuracy: 0.7619\n","Epoch 55/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9365\n","Epoch 55: val_accuracy did not improve from 0.76905\n","40/40 [==============================] - 10s 258ms/step - loss: 0.2045 - accuracy: 0.9365 - val_loss: 1.3396 - val_accuracy: 0.7476\n","Epoch 56/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9405\n","Epoch 56: val_accuracy did not improve from 0.76905\n","40/40 [==============================] - 10s 240ms/step - loss: 0.2048 - accuracy: 0.9405 - val_loss: 1.1178 - val_accuracy: 0.7476\n","Epoch 57/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9452\n","Epoch 57: val_accuracy did not improve from 0.76905\n","40/40 [==============================] - 11s 264ms/step - loss: 0.1907 - accuracy: 0.9452 - val_loss: 1.1294 - val_accuracy: 0.7405\n","Epoch 58/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9556\n","Epoch 58: val_accuracy improved from 0.76905 to 0.77619, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 273ms/step - loss: 0.1344 - accuracy: 0.9556 - val_loss: 1.0630 - val_accuracy: 0.7762\n","Epoch 59/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9587\n","Epoch 59: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 248ms/step - loss: 0.1315 - accuracy: 0.9587 - val_loss: 1.5544 - val_accuracy: 0.7143\n","Epoch 60/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9397\n","Epoch 60: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 248ms/step - loss: 0.2093 - accuracy: 0.9397 - val_loss: 1.2459 - val_accuracy: 0.7024\n","Epoch 61/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.9365\n","Epoch 61: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 11s 266ms/step - loss: 0.2267 - accuracy: 0.9365 - val_loss: 3.4836 - val_accuracy: 0.5262\n","Epoch 62/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.9183\n","Epoch 62: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 266ms/step - loss: 0.2699 - accuracy: 0.9183 - val_loss: 1.3520 - val_accuracy: 0.7429\n","Epoch 63/200\n","40/40 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9246\n","Epoch 63: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 253ms/step - loss: 0.2543 - accuracy: 0.9246 - val_loss: 1.3874 - val_accuracy: 0.7095\n","Epoch 64/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9405\n","Epoch 64: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 258ms/step - loss: 0.1874 - accuracy: 0.9405 - val_loss: 1.7051 - val_accuracy: 0.6810\n","Epoch 65/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9325\n","Epoch 65: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 11s 265ms/step - loss: 0.1939 - accuracy: 0.9325 - val_loss: 1.1068 - val_accuracy: 0.7690\n","Epoch 66/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9484\n","Epoch 66: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 11s 269ms/step - loss: 0.1697 - accuracy: 0.9484 - val_loss: 1.3186 - val_accuracy: 0.7452\n","Epoch 67/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9429\n","Epoch 67: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 252ms/step - loss: 0.1573 - accuracy: 0.9429 - val_loss: 1.1456 - val_accuracy: 0.7452\n","Epoch 68/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9325\n","Epoch 68: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 10s 241ms/step - loss: 0.1974 - accuracy: 0.9325 - val_loss: 1.3107 - val_accuracy: 0.7571\n","Epoch 69/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.9397\n","Epoch 69: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 11s 269ms/step - loss: 0.1970 - accuracy: 0.9397 - val_loss: 1.0525 - val_accuracy: 0.7595\n","Epoch 70/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9389\n","Epoch 70: val_accuracy did not improve from 0.77619\n","40/40 [==============================] - 11s 282ms/step - loss: 0.1950 - accuracy: 0.9389 - val_loss: 1.3668 - val_accuracy: 0.7071\n","Epoch 71/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9603\n","Epoch 71: val_accuracy improved from 0.77619 to 0.78810, saving model to cnn_aug.h5\n","40/40 [==============================] - 10s 259ms/step - loss: 0.1317 - accuracy: 0.9603 - val_loss: 0.9449 - val_accuracy: 0.7881\n","Epoch 72/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1468 - accuracy: 0.9460\n","Epoch 72: val_accuracy improved from 0.78810 to 0.79286, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 267ms/step - loss: 0.1468 - accuracy: 0.9460 - val_loss: 1.1520 - val_accuracy: 0.7929\n","Epoch 73/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9476\n","Epoch 73: val_accuracy did not improve from 0.79286\n","40/40 [==============================] - 11s 264ms/step - loss: 0.1504 - accuracy: 0.9476 - val_loss: 1.0835 - val_accuracy: 0.7738\n","Epoch 74/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9556\n","Epoch 74: val_accuracy did not improve from 0.79286\n","40/40 [==============================] - 10s 254ms/step - loss: 0.1388 - accuracy: 0.9556 - val_loss: 1.1708 - val_accuracy: 0.7619\n","Epoch 75/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.9492\n","Epoch 75: val_accuracy did not improve from 0.79286\n","40/40 [==============================] - 10s 254ms/step - loss: 0.1331 - accuracy: 0.9492 - val_loss: 1.2450 - val_accuracy: 0.7452\n","Epoch 76/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9563\n","Epoch 76: val_accuracy did not improve from 0.79286\n","40/40 [==============================] - 10s 260ms/step - loss: 0.1443 - accuracy: 0.9563 - val_loss: 1.3031 - val_accuracy: 0.7238\n","Epoch 77/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.9389\n","Epoch 77: val_accuracy did not improve from 0.79286\n","40/40 [==============================] - 10s 260ms/step - loss: 0.1712 - accuracy: 0.9389 - val_loss: 1.2561 - val_accuracy: 0.7643\n","Epoch 78/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9516\n","Epoch 78: val_accuracy did not improve from 0.79286\n","40/40 [==============================] - 10s 248ms/step - loss: 0.1645 - accuracy: 0.9516 - val_loss: 1.0483 - val_accuracy: 0.7881\n","Epoch 79/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9659\n","Epoch 79: val_accuracy improved from 0.79286 to 0.80476, saving model to cnn_aug.h5\n","40/40 [==============================] - 10s 259ms/step - loss: 0.1078 - accuracy: 0.9659 - val_loss: 0.9939 - val_accuracy: 0.8048\n","Epoch 80/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 0.9635\n","Epoch 80: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 10s 259ms/step - loss: 0.1424 - accuracy: 0.9635 - val_loss: 1.0999 - val_accuracy: 0.7952\n","Epoch 81/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9579\n","Epoch 81: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 11s 267ms/step - loss: 0.1370 - accuracy: 0.9579 - val_loss: 1.3014 - val_accuracy: 0.7667\n","Epoch 82/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.9643\n","Epoch 82: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 11s 261ms/step - loss: 0.1266 - accuracy: 0.9643 - val_loss: 1.1322 - val_accuracy: 0.7810\n","Epoch 83/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.9540\n","Epoch 83: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 11s 268ms/step - loss: 0.1503 - accuracy: 0.9540 - val_loss: 1.8252 - val_accuracy: 0.7048\n","Epoch 84/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.9540\n","Epoch 84: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 10s 259ms/step - loss: 0.1727 - accuracy: 0.9540 - val_loss: 1.2018 - val_accuracy: 0.7738\n","Epoch 85/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.9532\n","Epoch 85: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 10s 259ms/step - loss: 0.1502 - accuracy: 0.9532 - val_loss: 1.7025 - val_accuracy: 0.7095\n","Epoch 86/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9476\n","Epoch 86: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 10s 246ms/step - loss: 0.1899 - accuracy: 0.9476 - val_loss: 1.1735 - val_accuracy: 0.7571\n","Epoch 87/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.9603\n","Epoch 87: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 10s 257ms/step - loss: 0.1307 - accuracy: 0.9603 - val_loss: 1.1684 - val_accuracy: 0.7881\n","Epoch 88/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9508\n","Epoch 88: val_accuracy did not improve from 0.80476\n","40/40 [==============================] - 11s 262ms/step - loss: 0.1933 - accuracy: 0.9508 - val_loss: 1.7945 - val_accuracy: 0.7143\n","Epoch 89/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9603\n","Epoch 89: val_accuracy improved from 0.80476 to 0.82619, saving model to cnn_aug.h5\n","40/40 [==============================] - 11s 268ms/step - loss: 0.1300 - accuracy: 0.9603 - val_loss: 0.8995 - val_accuracy: 0.8262\n","Epoch 90/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9675\n","Epoch 90: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 247ms/step - loss: 0.0939 - accuracy: 0.9675 - val_loss: 1.1433 - val_accuracy: 0.7810\n","Epoch 91/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.9540\n","Epoch 91: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 259ms/step - loss: 0.1631 - accuracy: 0.9540 - val_loss: 1.4247 - val_accuracy: 0.7333\n","Epoch 92/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9627\n","Epoch 92: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 11s 264ms/step - loss: 0.1194 - accuracy: 0.9627 - val_loss: 1.1260 - val_accuracy: 0.7929\n","Epoch 93/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9706\n","Epoch 93: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 248ms/step - loss: 0.0794 - accuracy: 0.9706 - val_loss: 1.1046 - val_accuracy: 0.8071\n","Epoch 94/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9659\n","Epoch 94: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 238ms/step - loss: 0.1164 - accuracy: 0.9659 - val_loss: 1.4647 - val_accuracy: 0.7548\n","Epoch 95/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9619\n","Epoch 95: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 257ms/step - loss: 0.1024 - accuracy: 0.9619 - val_loss: 1.0679 - val_accuracy: 0.8167\n","Epoch 96/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9730\n","Epoch 96: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 254ms/step - loss: 0.0910 - accuracy: 0.9730 - val_loss: 2.2170 - val_accuracy: 0.6714\n","Epoch 97/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.9651\n","Epoch 97: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 250ms/step - loss: 0.1011 - accuracy: 0.9651 - val_loss: 1.0895 - val_accuracy: 0.8048\n","Epoch 98/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9690\n","Epoch 98: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 251ms/step - loss: 0.1138 - accuracy: 0.9690 - val_loss: 1.5525 - val_accuracy: 0.7619\n","Epoch 99/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0835 - accuracy: 0.9714\n","Epoch 99: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 11s 268ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 1.4107 - val_accuracy: 0.7762\n","Epoch 100/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9548\n","Epoch 100: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 255ms/step - loss: 0.1475 - accuracy: 0.9548 - val_loss: 1.0690 - val_accuracy: 0.8000\n","Epoch 101/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.9468\n","Epoch 101: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 248ms/step - loss: 0.1893 - accuracy: 0.9468 - val_loss: 1.6816 - val_accuracy: 0.7500\n","Epoch 102/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1334 - accuracy: 0.9595\n","Epoch 102: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 260ms/step - loss: 0.1334 - accuracy: 0.9595 - val_loss: 1.7369 - val_accuracy: 0.6976\n","Epoch 103/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.9690\n","Epoch 103: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 260ms/step - loss: 0.0968 - accuracy: 0.9690 - val_loss: 1.3986 - val_accuracy: 0.7929\n","Epoch 104/200\n","40/40 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9722\n","Epoch 104: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 253ms/step - loss: 0.0867 - accuracy: 0.9722 - val_loss: 2.3625 - val_accuracy: 0.6690\n","Epoch 105/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9571\n","Epoch 105: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 254ms/step - loss: 0.1317 - accuracy: 0.9571 - val_loss: 1.5242 - val_accuracy: 0.7024\n","Epoch 106/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9603\n","Epoch 106: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 11s 262ms/step - loss: 0.1160 - accuracy: 0.9603 - val_loss: 1.6401 - val_accuracy: 0.6762\n","Epoch 107/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9611\n","Epoch 107: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 11s 267ms/step - loss: 0.1430 - accuracy: 0.9611 - val_loss: 1.2139 - val_accuracy: 0.7762\n","Epoch 108/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9651\n","Epoch 108: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 10s 257ms/step - loss: 0.1264 - accuracy: 0.9651 - val_loss: 1.7051 - val_accuracy: 0.7357\n","Epoch 109/200\n","40/40 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9437\n","Epoch 109: val_accuracy did not improve from 0.82619\n","40/40 [==============================] - 12s 300ms/step - loss: 0.1744 - accuracy: 0.9437 - val_loss: 1.2700 - val_accuracy: 0.8000\n","Epoch 109: early stopping\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1753df0dff42e2b5ec66a7a4a0e885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▄▅▆▆▆▆▇▇▇▇▇██████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▁▃▄▅▆▅▇▇▇▄▇▇▇▇▇▇▇▇▇▅▇▇▇█▇█▇█▇██████▇█</td></tr><tr><td>epoch/val_loss</td><td>▄▆▄█▃▂▂▁▂▁▁▁▃▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.94365</td></tr><tr><td>epoch/epoch</td><td>108</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.17438</td></tr><tr><td>epoch/val_accuracy</td><td>0.8</td></tr><tr><td>epoch/val_loss</td><td>1.27003</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">vanilla-cnn-aug-classification-ucmerced</strong> at: <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/zefz29q8' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced/runs/zefz29q8</a><br/> View project at: <a href='https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced' target=\"_blank\">https://wandb.ai/igp-tubs/Vanilla%20CNN%20for%20image%20classification%20with%20UCMerced</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20240506_133742-zefz29q8/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"QRj63i5E4F5A"},"source":["## **Wandb logs**"]},{"cell_type":"markdown","metadata":{"id":"aPI3zoqQ4o4-"},"source":["Model training report: [Vanilla CNN for image classification using UCMerced](https://api.wandb.ai/links/igp-tubs/g9eamf3j)"]},{"cell_type":"markdown","metadata":{"id":"38gCzERMCRj3"},"source":["## **Testing the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDCFBmRUNU11"},"outputs":[],"source":["# Run this line to load a trained model\n","\n","# model_orig.load_weights(\"cnn_orig.h5\")\n","# model_aug.load_weights(\"cnn_aug.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181163,"status":"ok","timestamp":1715004277282,"user":{"displayName":"Pedro Marco Achanccaray Diaz","userId":"00866306694178948894"},"user_tz":-120},"id":"iuBzFsg32Ahs","outputId":"e358aa20-06a9-4b0d-f926-ed3b4f543727"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train:\n","40/40 [==============================] - 7s 173ms/step - loss: 0.9628 - accuracy: 0.8603\n","40/40 [==============================] - 8s 192ms/step - loss: 0.1525 - accuracy: 0.9532\n","Validation:\n","14/14 [==============================] - 2s 150ms/step - loss: 4.6400 - accuracy: 0.5119\n","14/14 [==============================] - 2s 151ms/step - loss: 1.2700 - accuracy: 0.8000\n","Test:\n","14/14 [==============================] - 112s 9s/step - loss: 4.2920 - accuracy: 0.5024\n","14/14 [==============================] - 2s 153ms/step - loss: 1.4794 - accuracy: 0.7714\n"]}],"source":["data_gen_test = DataGenerator(path_images=x_test,\n","                              labels=y_test,\n","                              batch_size=BATCH_SIZE,\n","                              n_classes=n_classes,\n","                              target_size=TARGET_SIZE,\n","                              shuffle=False)\n","\n","print(\"Train:\")\n","scores_train_orig = model_orig.evaluate(data_gen_train)\n","scores_train_aug = model_aug.evaluate(data_gen_train_aug)\n","\n","print(\"Validation:\")\n","scores_val_orig = model_orig.evaluate(data_gen_val)\n","scores_val_aug = model_aug.evaluate(data_gen_val)\n","\n","print(\"Test:\")\n","scores_test_orig = model_orig.evaluate(data_gen_test)\n","scores_test_aug = model_aug.evaluate(data_gen_test)"]},{"cell_type":"markdown","source":["<center>\n","\n","|             |Loss &darr;|              ||Accuracy &uarr;|      |\n","|:------------|:-------:|:------------:||:-------:|:------------:|\n","|**Model**    |**Train**|**Validation**||**Train**|**Validation**|\n","|w/o data augmentation| 0.96   |     4.64     ||   0.86  |     0.51     |\n","|w/ data augmentation |**0.15** |  **1.27**    || **0.95**|   **0.80**   |\n","\n","<br/><br/>\n","\n","|             |Loss &darr;||Accuracy &uarr;|\n","|:------------|:------:||:-------:|\n","|**Model**    |**Test**||**Test** |\n","|w/o data augmentation|  4.29  ||  0.50   |\n","|w/ data augmentation |**1.48**|| **0.77**|\n","\n","</center>\n"],"metadata":{"id":"CPxsv_D7tbIE"}}],"metadata":{"colab":{"collapsed_sections":["KhB2v5lPAYvF","GCZeFSPlAfEh","dmOB7awVHdOQ","J-XSWVHeBzRa","zoimN3cjB4OW","NcOX6uowBlDq","i3ammKZcRWqn","EyS5sA5SxSYe","ZcOA6hVa1PEE","TkaArXxnKH8L","5PFgRKW8KOcF","yYxjd9DIPVzG","GWA3F7NRPFsY","cxIMxNBkYpCD","x1gaZcnGbuie","dah4bJlO-rOW","oXjo2eGu1QHk","ks62-iBc8pzs","GpN8IibKyV8x","jg69GdoD93Yd","ZIZoBFZj-Wcf","kHjnjcKM-ZS2","QRj63i5E4F5A","38gCzERMCRj3"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e568754905394a3f9d4cf4a3b0c49b56":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e3c81037cf02449593a3779d0d1cd6ad","IPY_MODEL_676f87eeb9e24d96a29c0e9502d13f1e"],"layout":"IPY_MODEL_a22411c5481f4073ab520e8f70aa2ac3"}},"e3c81037cf02449593a3779d0d1cd6ad":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a89d50453b247dda47b9cf248b6899f","placeholder":"​","style":"IPY_MODEL_b5056a769c5644db9eac4652c31f9ead","value":"0.031 MB of 0.031 MB uploaded\r"}},"676f87eeb9e24d96a29c0e9502d13f1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_95a97c0609d34ee08740a38a9f29e6fb","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7987b2db48f406aa72ac4231736c364","value":1}},"a22411c5481f4073ab520e8f70aa2ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a89d50453b247dda47b9cf248b6899f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5056a769c5644db9eac4652c31f9ead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95a97c0609d34ee08740a38a9f29e6fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7987b2db48f406aa72ac4231736c364":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b1753df0dff42e2b5ec66a7a4a0e885":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e2e17267b1a84e94a667ee9a732e73a1","IPY_MODEL_2e54f439244c4ed9a2dc850030bb90d6"],"layout":"IPY_MODEL_689e9057a2ee43579d39fa7b6dc5c2c4"}},"e2e17267b1a84e94a667ee9a732e73a1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8659f9acacd4b0eb43b13427419ffed","placeholder":"​","style":"IPY_MODEL_1fb9a6f772d74b629bdd7a2a69794dbb","value":"0.074 MB of 0.074 MB uploaded\r"}},"2e54f439244c4ed9a2dc850030bb90d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_894d501224604081b3ffceec3a160976","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_306d232f0f6e4c2dae42584f1728f056","value":1}},"689e9057a2ee43579d39fa7b6dc5c2c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8659f9acacd4b0eb43b13427419ffed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb9a6f772d74b629bdd7a2a69794dbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"894d501224604081b3ffceec3a160976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"306d232f0f6e4c2dae42584f1728f056":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}